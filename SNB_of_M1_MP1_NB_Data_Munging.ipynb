{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7rc1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUUu9l_JfJ92"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "\n",
        "##  A program by IISc and TalentSprint\n",
        "\n",
        "### Mini Project Notebook 1 : Data analytics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3yrUc-XrLS"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nljJR6CwfZN_"
      },
      "source": [
        "\n",
        "\n",
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "\n",
        "* understand the requirements for a “clean” dataset, ready for use in statistical analysis\n",
        "\n",
        "* use Python libraries like Pandas, Numpy, and Matplotlib to perform the  data-preprocessing steps\n",
        "\n",
        "* obtain probability and statistics based insights from the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMh1cTQ0Y0wZ"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlCSHY5_Y0wb"
      },
      "source": [
        "The dataset chosen for this experiment is the **Play Store** dataset which is  publicly available and created with this [methodology](https://nycdatascience.com/blog/student-works/google-play-store-everything-that-you-need-to-know-about-the-android-market/)  \n",
        "\n",
        "This dataset consists of 10841 records. Each record is made up of 13 fields.\n",
        "\n",
        "**For example**, Each record consists of App, Category, Rating, Reviews, Size, Installs, Type, Price, Content Rating, Genres, Last Updated, Current Ver, and Android Ver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KovpIBt2Ztv8"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYdLgvhhZtwA"
      },
      "source": [
        "Before we can derive any meaningful insights from the Play Store data, it is essential to pre-process the data and make it suitable for further analysis. This pre-processing step forms a major part of data wrangling (or data munging) and ensures better quality data. It consists of the transformation and mapping of data from a \"raw\" data form into another format so that it is more valuable for a variety of downstream purposes such as analytics. Data analysts typically spend a sizeable amount of time in the process of data wrangling, compared to the actual analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqM_j0MiZtv-"
      },
      "source": [
        "After data munging is performed, several actionable insights can be derived from the Play Store apps data. Such insights could help to unlock the enormous potential to drive app-making businesses to success."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gi2zCP0ZtwB"
      },
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/Datasets/googleplaystore.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epVoy2b_Z05e"
      },
      "source": [
        "#### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1RX1oi_Z4Nu"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "import matplotlib.ticker as ticker\n",
        "from scipy import stats\n",
        "from scipy.stats import ttest_ind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmOJDVdp9PYo"
      },
      "source": [
        "#### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DrVCIg54LZp"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df_ = pd.read_csv('https://cdn.iisc.talentsprint.com/CDS/Datasets/googleplaystore.csv')\n",
        "df = df_.copy()\n",
        "print(df.head(5))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li5KS0i3pQqq"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSrwuDKposoF"
      },
      "source": [
        "### Task 1: Data Cleaning\n",
        "\n",
        "* Check whether there are any null values and figure out how you want to handle them?\n",
        "  \n",
        "    **Hint:** isnan(), dropna(), fillna()\n",
        "* If there is any duplication of a record, how would you like to handle it?\n",
        "\n",
        "    Hint: [drop_duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
        "\n",
        "* Are there any non-English apps? And how to filter them?\n",
        "\n",
        "* In the size column, multiply 1,000,000 with M in the cell and multiply by 1000 if we have K in the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgCf41v3FHLw"
      },
      "source": [
        "#YOUR CODE HERE\n",
        "null_values = df_.isna().sum()\n",
        "print(\"all columns with null\\n\\n\",null_values)\n",
        "\n",
        "#fill 0.0 for all null values of rating\n",
        "df['Rating'].fillna(0.0, inplace=True)\n",
        "\n",
        "# if price is 0, update type as free else paid.\n",
        "df['Type'] = np.where(df['Price'] == '0', 'Free', 'Paid')\n",
        "df.drop(df[df['Type']=='0'].index,inplace=True)\n",
        "\n",
        "\n",
        "#If Content Rating is nan, drop the record.\n",
        "df.dropna(subset=['Content Rating'], inplace=True)\n",
        "\n",
        "#if current ver is nan, fill it with the most occuring value\n",
        "df['Current Ver'].fillna(df_['Current Ver'].mode()[0], inplace=True)\n",
        "\n",
        "\n",
        "#if Android ver is nan, fill it with the most occuring value\n",
        "df['Android Ver'].fillna(df_['Android Ver'].mode()[0], inplace=True)\n",
        "\n",
        "#\n",
        "df['Installs'] = df['Installs'].str.replace(',', '').str.rstrip('+').astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicates\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "ligen_pGV9xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#non english apps\n",
        "df = df[df['App'].apply(lambda x: all(ord(char) < 128 for char in x))]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "njEV-0rkWblj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_size_to_numeric = lambda size_str: (\n",
        "    'Varies with device' if 'Varies with device' in size_str\n",
        "    else float(size_str.replace('M', '')) * 1_000_000 if 'M' in size_str\n",
        "    else float(size_str.replace('K', '')) * 1_000 if 'K' in size_str\n",
        "    else None\n",
        ")\n",
        "\n",
        "df['Size'] = df['Size'].apply(lambda x: convert_size_to_numeric(x) if pd.notna(x) else None)\n"
      ],
      "metadata": {
        "id": "HiXExyueu6dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrPzlHc4-zIR"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFgtC_jCpJL1"
      },
      "source": [
        "### Task 2: Perform the  following tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QQ2WUQX9XYy"
      },
      "source": [
        "##### Exercise 1: Find the number of apps in various categories by using an appropriate plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcRjzr9YRo72"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.countplot(y='Category', data=df, order=df['Category'].value_counts().index, palette='viridis')\n",
        "plt.title('Number of Apps in Various Categories')\n",
        "plt.xlabel('Number of Apps')\n",
        "plt.ylabel('Category')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzzEnMv25vGn"
      },
      "source": [
        "##### Exercise 2: Explore the distribution of free and paid apps across different categories\n",
        "\n",
        "**Hint:** Stacked Bar Graph, [link](https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/bar_stacked.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzxR7Gj4Rrbw"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Pivot the DataFrame to create a table for the stacked bar plot\n",
        "stacked_df = df.groupby(['Category', 'Type']).size().unstack()\n",
        "#sort by numbers of apps\n",
        "\n",
        "# Create a stacked bar plot\n",
        "stacked_df.plot(kind='bar', stacked=True, color=['green', 'red'], edgecolor='white', figsize=(14, 8))\n",
        "\n",
        "plt.title('Distribution of Free and Paid Apps Across Categories')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Number of Apps')\n",
        "\n",
        "# Add a legend for clarity\n",
        "plt.legend(title='App Type', loc='upper right')\n",
        "\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFNIQ4dj59Ep"
      },
      "source": [
        "##### Exercise 3: Represent the distribution of app rating on a scale of 1-5 using an appropriate plot\n",
        "\n",
        "**Hint:** histogram / strip plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZDWxb_JRtBl"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Histogram\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['Rating'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Histogram of App Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Strip Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.stripplot(x='Rating', data=df, jitter=True, alpha=0.7, color='salmon')\n",
        "plt.title('Strip Plot of App Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWglBy3pDK3g"
      },
      "source": [
        "\n",
        "##### Exercise 4: Identify outliers of the rating column by plotting the boxplot category wise and handle them.\n",
        "\n",
        "**Hint:** Removing outliers using Z-score, quantile [link](https://kanoki.org/2020/04/23/how-to-remove-outliers-in-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehVoOe9ARv0w"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "\n",
        "# Identify and handle outliers using Z-score\n",
        "df['Z_Score'] = zscore(df['Rating'])\n",
        "\n",
        "mean_z = np.mean(df['Z_Score'])\n",
        "std_z = np.std(df['Z_Score'])\n",
        "\n",
        "# Choose the multiplier based on the desired threshold (e.g., 2 for 95% confidence interval)\n",
        "threshold_multiplier = 2\n",
        "\n",
        "# Calculate the threshold\n",
        "threshold = mean_z + threshold_multiplier * std_z\n",
        "\n",
        "selected_column = df['Z_Score']\n",
        "\n",
        "# Create a new DataFrame with the selected column\n",
        "selected_column_df = pd.DataFrame({'Z_Score': selected_column})\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "selected_column_df.to_csv('Z_Score.csv', index=False)\n",
        "\n",
        "outliers = np.abs(df['Z_Score']) > threshold\n",
        "\n",
        "df_filtered=df[~outliers]\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Create a boxplot\n",
        "sns.boxplot(x='Category', y='Rating', data=df_filtered)\n",
        "plt.title('Boxplot of App Ratings by Category')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Rating')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiOWt855DsZ8"
      },
      "source": [
        "##### Exercise 5: Plot the barplot of all the categories indicating no. of installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3LW5CejRyBc"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# Assuming your DataFrame is named df\n",
        "# Create a bar plot using seaborn\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='Installs', y='Category', data=df, estimator=sum, errorbar=None)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Number of Installs by Category')\n",
        "plt.xlabel('Number of Installs')\n",
        "plt.ylabel('Category')\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLNboJI1bDhL"
      },
      "source": [
        "## Insights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boBhK2SdGXlW"
      },
      "source": [
        "### Task 3: Derive the below insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtVLkGB_ANwf"
      },
      "source": [
        "##### Exercise 1: Does the price correlate with the size of the app?\n",
        "\n",
        "  **Hint:** plot the scatterplot of `Size` and `Price`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDhPtmBCJC41"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# Assuming your DataFrame is named df\n",
        "df_drop_size = df[df['Size'] != 'Varies with device']\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Extract the Size and Price columns\n",
        "size = df_drop_size['Size']\n",
        "price = df_drop_size['Price']\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(size, price, alpha=0.5, color='blue')\n",
        "\n",
        "plt.title('Scatterplot of Size vs Price')\n",
        "plt.xlabel('Size')\n",
        "plt.ylabel('Price')\n",
        "plt.yscale('log')\n",
        "\n",
        "# Define a formatting function for the y-axis labels\n",
        "def price_formatter(x, pos):\n",
        "    return f\"${x:.0f}\"\n",
        "\n",
        "# Apply the formatting function to the y-axis labels\n",
        "plt.gca().get_yaxis().set_major_formatter(ticker.FuncFormatter(price_formatter))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#df.cor to get degree of correlation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqBPcp9rDcRh"
      },
      "source": [
        "##### Exercise 2: Find the popular app categories based on rating and no. of installs\n",
        "\n",
        "**Hint:** [df.groupby.agg()](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.core.groupby.DataFrameGroupBy.agg.html); Taking the average rating could be another approach\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWftl4eC2jNU"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "category_popularity = df.groupby('Category').agg({\n",
        "    'Rating': 'mean',\n",
        "    'Installs': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Calculate a combined metric based on the average rating and total installs\n",
        "category_popularity['CombinedMetric'] = category_popularity['Rating'] * category_popularity['Installs']\n",
        "\n",
        "# Sort categories based on popularity\n",
        "sorted_categories = category_popularity.sort_values(by='CombinedMetric', ascending=False)['Category']\n",
        "\n",
        "# Display the popular categories\n",
        "print(\"Popular App Categories based on Rating and Installs:\")\n",
        "print(category_popularity.loc[category_popularity['Category'].isin(sorted_categories)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kksy2sD4CMKQ"
      },
      "source": [
        "##### Exercise 3: How many apps are produced in each year category-wise ?\n",
        "\n",
        "  * Create a `Year` column by slicing the values of `Last Updated` column and find the Year with most no. of apps produced\n",
        "\n",
        "    **For example**, slice the year `2017` from `February 8, 2017`\n",
        "\n",
        "  * Find the categories which have a consistent rating in each year\n",
        "\n",
        "      **Hint:** `sns.countplot`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpnlYfHCO3P"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df['Last Updated'] = pd.to_datetime(df['Last Updated'])\n",
        "\n",
        "# Create a new 'Year' column by extracting the year\n",
        "df['Year'] = df['Last Updated'].dt.year\n",
        "\n",
        "# Count the number of apps produced in each year category-wise\n",
        "apps_per_year = df.groupby(['Year', 'Category']).size().reset_index(name='Count')\n",
        "\n",
        "# Find the year with the most number of apps produced\n",
        "most_apps_year = apps_per_year.loc[apps_per_year['Count'].idxmax()]\n",
        "\n",
        "print(\"Apps produced in each year category-wise:\")\n",
        "print(apps_per_year)\n",
        "\n",
        "print(\"\\nYear with the most number of apps produced:\")\n",
        "print(most_apps_year[['Year', 'Count']])\n",
        "\n",
        "#add a timeseries line chart or a countplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Last Updated'] = pd.to_datetime(df['Last Updated'])\n",
        "\n",
        "# Create a new 'Year' column by extracting the year\n",
        "df['Year'] = df['Last Updated'].dt.year\n",
        "\n",
        "# Calculate the standard deviation of ratings for each category in each year\n",
        "rating_std_by_category = df.groupby(['Year', 'Category'])['Rating'].std().reset_index()\n",
        "\n",
        "# Calculate the mean standard deviation for each category across years\n",
        "mean_std_by_category = rating_std_by_category.groupby('Category')['Rating'].mean().reset_index()\n",
        "\n",
        "# Sort categories based on mean standard deviation in ascending order\n",
        "consistent_categories = mean_std_by_category.sort_values(by='Rating', )\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a bar plot to visualize mean standard deviation for each category\n",
        "sns.barplot(x='Rating', y='Category', data=consistent_categories, palette='viridis')\n",
        "\n",
        "# Set plot labels and title\n",
        "plt.xlabel('Mean Standard Deviation of Ratings')\n",
        "plt.ylabel('Category')\n",
        "plt.title('Consistency of Ratings Across Categories')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "#sort it out by highest rating to lowest"
      ],
      "metadata": {
        "id": "HdaAAdwQ47a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnhRhfWadnGK"
      },
      "source": [
        "##### Exercise 4: Identify the highest paid apps with a good rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LmV1w_JdvRg"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df['Price'] = pd.to_numeric(df['Price'].replace('[\\$,]', '', regex=True), errors='coerce')\n",
        "\n",
        "# Filter for paid apps\n",
        "paid_apps = df[df['Type'] == 'Paid']\n",
        "\n",
        "# Set a threshold for a \"good\" rating (adjust as needed)\n",
        "good_rating_threshold = 4.5\n",
        "\n",
        "# Filter for paid apps with a good rating\n",
        "good_paid_apps = paid_apps[paid_apps['Rating'] >= good_rating_threshold]\n",
        "\n",
        "# Sort the good paid apps by rating in descending order\n",
        "highest_paid_good_apps = good_paid_apps.sort_values(by='Rating', ascending=False)\n",
        "\n",
        "# Display the highest paid apps with a good rating\n",
        "print(\"Highest Paid Apps with a Good Rating:\")\n",
        "print(highest_paid_good_apps[['App', 'Rating', 'Price']])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSCEb0GX5-d1"
      },
      "source": [
        "##### Exercise 5: Are the top-rated apps genuine ? How about checking reviews count of top-rated apps ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8kGpmMmx7HI"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df['Reviews'] = pd.to_numeric(df['Reviews'], errors='coerce')\n",
        "\n",
        "# Set a threshold for a \"top-rated\" app (adjust as needed)\n",
        "top_rated_threshold = 4.5\n",
        "\n",
        "# Filter for top-rated apps\n",
        "top_rated_apps = df[df['Rating'] >= top_rated_threshold]\n",
        "\n",
        "# Sort the top-rated apps by reviews count in descending order\n",
        "top_rated_apps = top_rated_apps.sort_values(by='Rating', ascending=False)\n",
        "\n",
        "# Display the top-rated apps along with their ratings and reviews count\n",
        "print(\"Top-Rated Apps with High Reviews Count:\")\n",
        "print(top_rated_apps[['App', 'Rating', 'Reviews']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXQfqIixzC4_"
      },
      "source": [
        "##### Exercise 6: If the number of reviews of an app is very low, what could be the reason for its top-rating ?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It could be a newly launched app which very few people have installed and whoever has installed has rated it high."
      ],
      "metadata": {
        "id": "Fky2suPk-NFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Exercise 7: What is the 95% confidence interval for the rating of apps in the Google Play Store?"
      ],
      "metadata": {
        "id": "OGMPVx-oLVDM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCqAHD0OLyFj"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
        "\n",
        "# Calculate mean and standard deviation\n",
        "mean_rating = np.mean(df['Rating'])\n",
        "std_dev_rating = np.std(df['Rating'], ddof=1)\n",
        "\n",
        "# Calculate the 95% confidence interval\n",
        "confidence_interval = stats.norm.interval(0.95, loc=mean_rating, scale=std_dev_rating/np.sqrt(len(df['Rating'])))\n",
        "\n",
        "print(\"95% Confidence Interval for Rating:\")\n",
        "print(confidence_interval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Exercise 8: Test if there is a statistically significant difference in the ratings between free and paid apps using a t-test\n",
        "\n",
        "Steps:\n",
        "\n",
        "* Set the null hypothesis and alternate hypothesis\n",
        "* Separate the ratings of free and paid apps.\n",
        "* Perform t-test: Use an independent samples t-test.\n",
        "* Interpret results based on the p-value, decide whether to reject or fail to reject the null hypothesis."
      ],
      "metadata": {
        "id": "yTwkV1aqJ2VL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):**\n",
        "There is no significant difference in ratings between free and paid apps.\n",
        "\n",
        "**Alternative Hypothesis (H1):**\n",
        "There is a significant difference in ratings between free and paid apps."
      ],
      "metadata": {
        "id": "_NJ5lxsEAeRS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxxay7xvLA2U"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# Separate ratings of free and paid apps\n",
        "ratings_free = df[df['Type'] == 'Free']['Rating']\n",
        "ratings_paid = df[df['Type'] == 'Paid']['Rating']\n",
        "\n",
        "# Perform independent samples t-test\n",
        "t_statistic, p_value = ttest_ind(ratings_free, ratings_paid, equal_var=False)\n",
        "\n",
        "# Set significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Interpret the results\n",
        "print(\"t-statistic:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference in ratings between free and paid apps.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in ratings between free and paid apps.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}